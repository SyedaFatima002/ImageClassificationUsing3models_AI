{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSk6r-Lk7GYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb8c8dd-1059-4551-e9eb-8e42efd0a1a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/data\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/data')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Function to preprocess image\n",
        "def preprocess_image(image_path):\n",
        "    # Loading and preprocessing image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (224, 224))  # Resizing the image to match ResNet input size\n",
        "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Converting BGR to RGB\n",
        "    image = image.astype(np.float32) / 255.0  # Normalizing pixel values\n",
        "    return image\n",
        "\n",
        "# Function to parse the label file\n",
        "def parse_label_file(label_file_path):\n",
        "    labels = []\n",
        "    with open(label_file_path, 'r') as label_file:\n",
        "        for line in label_file:\n",
        "            values = line.split()\n",
        "            class_index = int(values[0])\n",
        "            labels.append(class_index)\n",
        "    return labels\n",
        "\n",
        "# Function to load dataset\n",
        "def load_dataset(data_dir, num_classes, test=False):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # Paths to images and their corresponding label files\n",
        "    images_dir = os.path.join(data_dir, \"images\")\n",
        "    labels_dir = os.path.join(data_dir, \"labels\")\n",
        "\n",
        "    for image_name in os.listdir(images_dir):\n",
        "        image_path = os.path.join(images_dir, image_name)\n",
        "        # Preprocessing the original image\n",
        "        original_image = preprocess_image(image_path)\n",
        "        images.append(original_image)\n",
        "\n",
        "        # Reading labels from the corresponding label file if it exists\n",
        "        label_file_path = os.path.join(labels_dir, os.path.splitext(image_name)[0] + \".txt\")\n",
        "        if os.path.exists(label_file_path):\n",
        "            label_vector = parse_label_file(label_file_path)\n",
        "            labels.append(label_vector)\n",
        "        else:\n",
        "            # If the label file is missing, mark the label as an empty list\n",
        "            labels.append([])\n",
        "\n",
        "    # Converting the labels to binary format using MultiLabelBinarizer\n",
        "    mlb = MultiLabelBinarizer(classes=range(num_classes))\n",
        "    labels = mlb.fit_transform(labels)\n",
        "\n",
        "    return np.array(images), labels\n",
        "\n",
        "# Specifying the path dataset directories and the number of classes\n",
        "train_data_dir = \"/content/data/My Drive/AI_Project/train\"\n",
        "test_data_dir = \"/content/data/My Drive/AI_Project/test\"\n",
        "val_data_dir = \"/content/data/My Drive/AI_Project/valid\"\n",
        "num_classes = 10\n",
        "\n",
        "# Loading and preprocessing the training dataset\n",
        "train_images, train_labels = load_dataset(train_data_dir, num_classes)\n",
        "print(\"Shape of training images array:\", train_images.shape)\n",
        "print(\"Shape of training labels array:\", train_labels.shape)\n",
        "\n",
        "# Loading and preprocessing the validation dataset\n",
        "val_images, val_labels = load_dataset(val_data_dir, num_classes)\n",
        "print(\"Shape of validation images array:\", val_images.shape)\n",
        "print(\"Shape of validation labels array:\", val_labels.shape)\n",
        "\n",
        "# Loading and preprocessing the test dataset\n",
        "test_images, test_labels = load_dataset(test_data_dir, num_classes, test=True)\n",
        "print(\"Shape of test images array:\", test_images.shape)\n",
        "print(\"Shape of test labels array:\", test_labels.shape)\n"
      ],
      "metadata": {
        "id": "6zMDocBh7urc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f0e193-3dfa-4c86-9edd-add0501da955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training images array: (1012, 224, 224, 3)\n",
            "Shape of training labels array: (1012, 10)\n",
            "Shape of validation images array: (230, 224, 224, 3)\n",
            "Shape of validation labels array: (230, 10)\n",
            "Shape of test images array: (107, 224, 224, 3)\n",
            "Shape of test labels array: (107, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is35JwmAIik1",
        "outputId": "8c3a0d1d-7ab7-4041-d93b-fa2a7fe374d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 838s 25s/step - loss: 959.4907 - accuracy: 0.2984 - val_loss: 3346.5056 - val_accuracy: 0.4217\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 782s 24s/step - loss: 3158.7524 - accuracy: 0.2520 - val_loss: 1418.5485 - val_accuracy: 0.1957\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 775s 24s/step - loss: 5340.3491 - accuracy: 0.2559 - val_loss: 38579.2773 - val_accuracy: 0.1957\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 768s 24s/step - loss: 12936.8223 - accuracy: 0.2579 - val_loss: 18302.9551 - val_accuracy: 0.1957\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 767s 24s/step - loss: 25561.6562 - accuracy: 0.2727 - val_loss: 67.7590 - val_accuracy: 0.3652\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 769s 24s/step - loss: 35767.5625 - accuracy: 0.3686 - val_loss: 49.5805 - val_accuracy: 0.4348\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 765s 24s/step - loss: 61274.3438 - accuracy: 0.3844 - val_loss: 655.5873 - val_accuracy: 0.1957\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 804s 25s/step - loss: 102757.5391 - accuracy: 0.3567 - val_loss: 3.2327 - val_accuracy: 0.4217\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 765s 24s/step - loss: 128107.7344 - accuracy: 0.3646 - val_loss: 2927.6443 - val_accuracy: 0.3696\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 766s 24s/step - loss: 223887.8438 - accuracy: 0.2905 - val_loss: 28.6226 - val_accuracy: 0.1870\n",
            "8/8 [==============================] - 39s 5s/step - loss: 28.6226 - accuracy: 0.1870\n",
            "Validation Loss: 28.622596740722656\n",
            "Validation Accuracy: 0.186956524848938\n",
            "4/4 [==============================] - 19s 4s/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Test Loss: 0.0\n",
            "Test Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate 0.001\n",
        "# batchsize = 32\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Loading the pre-trained ResNet model without classifier head\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freezing the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Adding a custom classifier head\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "x = Dense(256, activation='relu')(x)  # Adding another dense layer\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "x = Dense(128, activation='relu')(x)  # Adding another dense layer\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "x = Dense(64, activation='relu')(x)  # Adding another dense layer\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "# Creating final model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compiling model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Defining early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training the model with early stopping\n",
        "history = model.fit(train_images, train_labels, epochs=30, batch_size=32,\n",
        "                    validation_data=(val_images, val_labels), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluating the model on validation data\n",
        "val_loss, val_accuracy = model.evaluate(val_images, val_labels)\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Testing the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "iIJBpYffqX2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add7fdd2-b64f-43bd-e1fa-c3a1b4e1611c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "Epoch 1/30\n",
            "32/32 [==============================] - 255s 8s/step - loss: 25.6556 - accuracy: 0.1670 - val_loss: 3.6140 - val_accuracy: 0.3696\n",
            "Epoch 2/30\n",
            "32/32 [==============================] - 248s 8s/step - loss: 9.7673 - accuracy: 0.2115 - val_loss: 4.7152 - val_accuracy: 0.3696\n",
            "Epoch 3/30\n",
            "32/32 [==============================] - 295s 9s/step - loss: 78.5749 - accuracy: 0.2520 - val_loss: 149.1138 - val_accuracy: 0.3696\n",
            "Epoch 4/30\n",
            "32/32 [==============================] - 248s 8s/step - loss: 3359.0999 - accuracy: 0.2421 - val_loss: 6275.8545 - val_accuracy: 0.3696\n",
            "Epoch 5/30\n",
            "32/32 [==============================] - 296s 9s/step - loss: 66594.5938 - accuracy: 0.2381 - val_loss: 91362.0469 - val_accuracy: 0.3696\n",
            "Epoch 6/30\n",
            "32/32 [==============================] - 250s 8s/step - loss: 614855.8125 - accuracy: 0.2223 - val_loss: 472193.2500 - val_accuracy: 0.3696\n",
            "8/8 [==============================] - 41s 5s/step - loss: 3.6140 - accuracy: 0.3696\n",
            "Validation Loss: 3.6140222549438477\n",
            "Validation Accuracy: 0.3695652186870575\n",
            "4/4 [==============================] - 18s 4s/step - loss: 7.2073 - accuracy: 0.2897\n",
            "Test Loss: 7.207307815551758\n",
            "Test Accuracy: 0.2897196114063263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate 0.01\n",
        "# batchsize = 32\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Loading the pre-trained ResNet model without classifier head\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freezing the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Adding a custom classifier head\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "x = Dense(256, activation='relu')(x)  # Adding another dense layer\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "x = Dense(128, activation='relu')(x)  # Adding another dense layer\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "x = Dense(64, activation='relu')(x)  # Adding another dense layer\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "# Creating final model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compiling model\n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Defining early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training the model with early stopping\n",
        "history = model.fit(train_images, train_labels, epochs=30, batch_size=32,\n",
        "                    validation_data=(val_images, val_labels), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluating the model on validation data\n",
        "val_loss, val_accuracy = model.evaluate(val_images, val_labels)\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Testing the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Wlanrm6mNmc5",
        "outputId": "a38e96f8-4803-4e56-b96e-fd2047ac4b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'num_classes' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b1dda842a441>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adding another dense layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adding dropout for regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_classes' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate 0.001\n",
        "# Batch size 16\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Loading the pre-trained ResNet model without classifier head\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freezing the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Adding a custom classifier head\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "x = Dense(256, activation='relu')(x)  # Adding another dense layer\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "x = Dense(128, activation='relu')(x)  # Adding another dense layer\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "x = Dense(64, activation='relu')(x)  # Adding another dense layer\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "# Creating final model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compiling model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Defining early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training the model with early stopping\n",
        "history = model.fit(train_images, train_labels, epochs=30, batch_size=16,\n",
        "                    validation_data=(val_images, val_labels), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluating the model on validation data\n",
        "val_loss, val_accuracy = model.evaluate(val_images, val_labels)\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Testing the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "Kl__-XiYNqMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479b4a19-50df-4ae8-8148-d50be539df3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "64/64 [==============================] - 371s 6s/step - loss: 36.5539 - accuracy: 0.1976 - val_loss: 25.2588 - val_accuracy: 0.3696\n",
            "Epoch 2/30\n",
            "64/64 [==============================] - 342s 5s/step - loss: 2153.4602 - accuracy: 0.2441 - val_loss: 8572.5166 - val_accuracy: 0.3696\n",
            "Epoch 3/30\n",
            "64/64 [==============================] - 340s 5s/step - loss: 430896.1562 - accuracy: 0.2540 - val_loss: 957462.6875 - val_accuracy: 0.4087\n",
            "Epoch 4/30\n",
            "64/64 [==============================] - 340s 5s/step - loss: 9313203.0000 - accuracy: 0.2372 - val_loss: 14357632.0000 - val_accuracy: 0.3696\n",
            "Epoch 5/30\n",
            "64/64 [==============================] - 346s 5s/step - loss: 54879372.0000 - accuracy: 0.2164 - val_loss: 60991960.0000 - val_accuracy: 0.3696\n",
            "Epoch 6/30\n",
            "64/64 [==============================] - 302s 5s/step - loss: 196436096.0000 - accuracy: 0.2362 - val_loss: 171343264.0000 - val_accuracy: 0.1957\n",
            "8/8 [==============================] - 48s 6s/step - loss: 25.2588 - accuracy: 0.3696\n",
            "Validation Loss: 25.258764266967773\n",
            "Validation Accuracy: 0.3695652186870575\n",
            "4/4 [==============================] - 23s 5s/step - loss: 73.5548 - accuracy: 0.2897\n",
            "Test Loss: 73.55481719970703\n",
            "Test Accuracy: 0.2897196114063263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate 0.01\n",
        "# Batch size 16\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Loading the pre-trained ResNet model without classifier head\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freezing the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Adding a custom classifier head\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "x = Dense(256, activation='relu')(x)  # Adding another dense layer\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "x = Dense(128, activation='relu')(x)  # Adding another dense layer\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "x = Dense(64, activation='relu')(x)  # Adding another dense layer\n",
        "x = Dropout(0.5)(x)  # Adding dropout for regularization\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "# Creating final model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compiling model\n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Defining early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training the model with early stopping\n",
        "history = model.fit(train_images, train_labels, epochs=30, batch_size=16,\n",
        "                    validation_data=(val_images, val_labels), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluating the model on validation data\n",
        "val_loss, val_accuracy = model.evaluate(val_images, val_labels)\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Testing the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "IkcezXIjOFK1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}